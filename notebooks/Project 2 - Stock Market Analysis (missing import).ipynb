{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Project - Stock Market Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your second data project! In this portfolio project we will be looking at data from the stock market, particularly some technology stocks. We will learn how to use pandas to get stock information, visualize different aspects of it, and finally we will look at a few ways of analyzing the risk of a stock, based on its previous performance history. We will also be predicting future stock prices through a Monte Carlo method!\n",
    "\n",
    "We'll be answering the following questions along the way:\n",
    "\n",
    "    1.) What was the change in price of the stock over time?\n",
    "    2.) What was the daily return of the stock on average?\n",
    "    3.) What was the moving average of the various stocks?\n",
    "    4.) What was the correlation between different stocks' closing prices?\n",
    "    4.) What was the correlation between different stocks' daily returns?\n",
    "    5.) How much value do we put at risk by investing in a particular stock?\n",
    "    6.) How can we attempt to predict future stock behavior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Basic Analysis of Stock Information\n",
    "\n",
    "In this section we'll go over how to handle requesting stock information with pandas, and how to analyze basic attributes of a stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas.io.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e8c68385e5a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# For reading stock data from yahoo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# For time stamps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas.io.data'"
     ]
    }
   ],
   "source": [
    "#Let's go ahead and start with some imports\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "import numpy as np\n",
    "\n",
    "# For Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# For reading stock data from yahoo\n",
    "from pandas.io.data import DataReader\n",
    "\n",
    "# For time stamps\n",
    "from datetime import datetime\n",
    "\n",
    "# For division\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Yahoo and pandas to grab some data for some tech stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tech stocks we'll use for this analysis\n",
    "tech_list = ['AAPL','GOOG','MSFT','AMZN']\n",
    "\n",
    "# Set up End and Start times for data grab\n",
    "end = datetime.now()\n",
    "start = datetime(end.year - 1,end.month,end.day)\n",
    "\n",
    "\n",
    "#For loop for grabing yahoo finance data and setting as a dataframe\n",
    "\n",
    "for stock in tech_list:   \n",
    "    # Set DataFrame as the Stock Ticker\n",
    "    globals()[stock] = DataReader(stock,'yahoo',start,end)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick note: Using globals() is a sloppy way of setting the DataFrame names, but its simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and play aorund with the AAPL DataFrame to get a feel for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Stats\n",
    "AAPL.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Info\n",
    "AAPL.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen the DataFrame, let's go ahead and plot out the volume and closing price of the stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see a historical view of the closing price\n",
    "AAPL['Adj Close'].plot(legend=True,figsize=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's plot the total volume of stock being traded each day over the past 5 years\n",
    "AAPL['Volume'].plot(legend=True,figsize=(10,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen the visualizations for the closing price and the volume traded each day, let's go ahead and caculate the moving average for the stock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more info on the moving average check out the following links:\n",
    "\n",
    "1.) http://www.investopedia.com/terms/m/movingaverage.asp\n",
    "\n",
    "2.) http://www.investopedia.com/articles/active-trading/052014/how-use-moving-average-buy-stocks.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luckily pandas has a built-in rolling mean calculator\n",
    "\n",
    "# Let's go ahead and plot out several moving averages\n",
    "ma_day = [10,20,50]\n",
    "\n",
    "for ma in ma_day:\n",
    "    column_name = \"MA for %s days\" %(str(ma))\n",
    "    AAPL[column_name]=pd.rolling_mean(AAPL['Adj Close'],ma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go ahead and plot all the additional Moving Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL[['Adj Close','MA for 10 days','MA for 20 days','MA for 50 days']].plot(subplots=False,figsize=(10,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2 - Daily Return Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've done some baseline analysis, let's go ahead and dive a little deeper. We're now going to analyze the risk of the stock. In order to do so we'll need to take a closer look at the daily changes of the stock, and not just its absolute value. Let's go ahead and use pandas to retrieve teh daily returns for the Apple stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use pct_change to find the percent change for each day\n",
    "AAPL['Daily Return'] = AAPL['Adj Close'].pct_change()\n",
    "# Then we'll plot the daily return percentage\n",
    "AAPL['Daily Return'].plot(figsize=(12,4),legend=True,linestyle='--',marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's get an overall look at the average daily return using a histogram. We'll use seaborn to create both a histogram and kde plot on the same figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the use of dropna() here, otherwise the NaN values can't be read by seaborn\n",
    "sns.distplot(AAPL['Daily Return'].dropna(),bins=100,color='purple')\n",
    "\n",
    "# Could have also done:\n",
    "#AAPL['Daily Return'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what if we wanted to analyze the returns of all the stocks in our list? Let's go ahead and build a DataFrame with all the ['Close'] columns for each of the stocks dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all the closing prices for the tech stock list into one DataFrame\n",
    "closing_df = DataReader(['AAPL','GOOG','MSFT','AMZN'],'yahoo',start,end)['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a quick look\n",
    "closing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the closing prices, let's go ahead and get the daily return for all the stocks, like we did for the Apple stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new tech returns DataFrame\n",
    "tech_rets = closing_df.pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the daily percentage return of two stocks to check how correlated. First let's see a sotck compared to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing Google to itself should show a perfectly linear relationship\n",
    "sns.jointplot('GOOG','GOOG',tech_rets,kind='scatter',color='seagreen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can see that if two stocks are perfectly (and positivley) correlated with each other a linear relationship bewteen its daily return values should occur. So let's go ahead and compare Google and Microsoft the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use joinplot to compare the daily returns of Google and Microsoft\n",
    "sns.jointplot('GOOG','MSFT',tech_rets,kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intersting, the pearsonr value (officially known as the Pearson product-moment correlation coefficient) can give you a sense of how correlated the daily percentage returns are. You can find more information about it at this link:\n",
    "\n",
    "url - http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient\n",
    "\n",
    "But for a quick intuitive sense, check out the picture below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "SVG(url='http://upload.wikimedia.org/wikipedia/commons/d/d4/Correlation_examples2.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn and pandas make it very easy to repeat this comparison analysis for every possible combination of stocks in our technology stock ticker list. We can use sns.pairplot() to automatically create this plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can simply call pairplot on our DataFrame for an automatic visual analysis of all the comparisons\n",
    "sns.pairplot(tech_rets.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see all the relationships on daily returns between all the stocks. A quick glance shows an interesting correlation between Google and Amazon daily returns. It might be interesting to investigate that individual comaprison. While the simplicity of just calling sns.pairplot() is fantastic we can also use sns.PairGrid() for full control of the figure, including what kind of plots go in the diagonal, the upper triangle, and the lower triangle. Below is an example of utilizing the full power of seaborn to achieve this result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our figure by naming it returns_fig, call PairPLot on the DataFrame\n",
    "returns_fig = sns.PairGrid(tech_rets.dropna())\n",
    "\n",
    "# Using map_upper we can specify what the upper triangle will look like.\n",
    "returns_fig.map_upper(plt.scatter,color='purple')\n",
    "\n",
    "# We can also define the lower triangle in the figure, inclufing the plot type (kde) or the color map (BluePurple)\n",
    "returns_fig.map_lower(sns.kdeplot,cmap='cool_d')\n",
    "\n",
    "# Finally we'll define the diagonal as a series of histogram plots of the daily return\n",
    "returns_fig.map_diag(plt.hist,bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have also analyzed the correlation of the closing prices using this exact same technique. Here it is shown, the code repeated from above with the exception of the DataFrame called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up our figure by naming it returns_fig, call PairPLot on the DataFrame\n",
    "returns_fig = sns.PairGrid(closing_df)\n",
    "\n",
    "# Using map_upper we can specify what the upper triangle will look like.\n",
    "returns_fig.map_upper(plt.scatter,color='purple')\n",
    "\n",
    "# We can also define the lower triangle in the figure, inclufing the plot type (kde) or the color map (BluePurple)\n",
    "returns_fig.map_lower(sns.kdeplot,cmap='cool_d')\n",
    "\n",
    "# Finally we'll define the diagonal as a series of histogram plots of the closing price\n",
    "returns_fig.map_diag(plt.hist,bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we could also do a correlation plot, to get actual numerical values for the correlation between the stocks' daily return values. By comparing the closing prices, we see an interesting relationship between Microsoft and Apple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go ahead and use sebron for a quick correlation plot for the daily returns\n",
    "sns.corrplot(tech_rets.dropna(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! Just like we suspected in our PairPlot we see here numerically and visually that Amazon and Google had the strongest correlation of daily stock return. It's also interesting to see that all the technology comapnies are positively correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we've done some daily return analysis, let's go ahead and start looking deeper into actual risk analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Risk Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways we can quantify risk, one of the most basic ways using the information we've gathered on daily percentage returns is by comparing the expected return with the standard deviation of the daily returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by defining a new DataFrame as a clenaed version of the oriignal tech_rets DataFrame\n",
    "rets = tech_rets.dropna()\n",
    "\n",
    "area = np.pi*20\n",
    "\n",
    "plt.scatter(rets.mean(), rets.std(),alpha = 0.5,s =area)\n",
    "\n",
    "# Set the x and y limits of the plot (optional, remove this if you don't see anything in your plot)\n",
    "plt.ylim([0.01,0.025])\n",
    "plt.xlim([-0.003,0.004])\n",
    "\n",
    "#Set the plot axis titles\n",
    "plt.xlabel('Expected returns')\n",
    "plt.ylabel('Risk')\n",
    "\n",
    "# Label the scatter plots, for more info on how this is done, chekc out the link below\n",
    "# http://matplotlib.org/users/annotations_guide.html\n",
    "for label, x, y in zip(rets.columns, rets.mean(), rets.std()):\n",
    "    plt.annotate(\n",
    "        label, \n",
    "        xy = (x, y), xytext = (50, 50),\n",
    "        textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "        arrowprops = dict(arrowstyle = '-', connectionstyle = 'arc3,rad=-0.3'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value at Risk\n",
    "\n",
    "Let's go ahead and define a value at risk parameter for our stocks. We can treat value at risk as the amount of money we could  expect to lose (aka putting at risk) for a given confidence interval. Theres several methods we can use for estimating a value at risk. Let's go ahead and see some of them in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value at risk using the \"bootstrap\" method\n",
    "\n",
    "For this method we will calculate the empirical quantiles from a histogram of daily returns. For more information on quantiles, check out this link: http://en.wikipedia.org/wiki/Quantile\n",
    "\n",
    "Let's go ahead and repeat the daily returns histogram for Apple stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the use of dropna() here, otherwise the NaN values can't be read by seaborn\n",
    "sns.distplot(AAPL['Daily Return'].dropna(),bins=100,color='purple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use quantile to get the risk value for the stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 0.05 empirical quantile of daily returns\n",
    "rets['AAPL'].quantile(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 0.05 empirical quantile of daily returns is at -0.019. That means that with 95% confidence, our worst daily loss will not exceed 1.9%. If we have a 1 million dollar investment, our one-day 5% VaR is 0.019 * 1,000,000 = $19,000.\n",
    "\n",
    "Go ahead and repeat this for the other stocks in out portfolio, then afterwards we'll look at value at risk by implementing a Monte Carlo method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Value at Risk using the Monte Carlo method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Monte Carlo to run many trials with random market conditions, then we'll calculate portfolio losses for each trial. After this, we'll use the aggregation of all these simulations to establish how risky the stock is.\n",
    "\n",
    "Let's start with a brief explanation of what we're going to do:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the geometric Brownian motion (GBM), which is technically known as a Markov process. This means that the stock price follows a random walk and is consistent with (at the very least) the weak form of the efficient market hypothesis (EMH): past price information is already incorporated and the next price movement is \"conditionally independent\" of past price movements.\n",
    "\n",
    "This means that the past information on the price of a stock is independent of where the stock price will be in the future, basically meaning, you can't perfectly predict the future solely based on the previous price of a stock.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equation for geometric Browninan motion is given by the following equation:\n",
    "\n",
    "$$\\frac{\\Delta S}{S} = \\mu\\Delta t + \\sigma \\epsilon \\sqrt{\\Delta t}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where S is the stock price, mu is the expected return (which we calculated earlier),sigma is the standard deviation of the returns, t is time, and epsilon is the random variable.\n",
    "\n",
    "We can mulitply both sides by the stock price (S) to rearrange the formula and solve for the stock price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\Delta S = S(\\mu\\Delta t + \\sigma \\epsilon \\sqrt{\\Delta t}) $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that the change in the stock price is the current stock price multiplied by two terms. The first term is known as \"drift\", which is the average daily return multiplied by the change of time. The second term is known as \"shock\", for each tiem period the stock will \"drift\" and then experience a \"shock\" which will randomly push the stock price up or down. By simulating this series of steps of drift and shock thousands of times, we can begin to do a simulation of where we might expect the stock price to be.\n",
    "\n",
    "For more info on the Monte Carlo method for stocks, check out the following link:\n",
    "http://www.investopedia.com/articles/07/montecarlo.asp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate a basic Monte Carlo method, we will start with just a few simulations. First we'll define the variables we'll be using the Google DataFrame GOOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our time horizon\n",
    "days = 365\n",
    "\n",
    "# Now our delta\n",
    "dt = 1/days\n",
    "\n",
    "# Now let's grab our mu (drift) from the expected return data we got for AAPL\n",
    "mu = rets.mean()['GOOG']\n",
    "\n",
    "# Now let's grab the volatility of the stock from the std() of the average return\n",
    "sigma = rets.std()['GOOG']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a function that takes in the starting price and number of days, and uses teh sigma and mu we already calculated form out daily returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_monte_carlo(start_price,days,mu,sigma):\n",
    "    ''' This function takes in starting stock price, days of simulation,mu,sigma, and returns simulated price array'''\n",
    "    \n",
    "    # Define a price array\n",
    "    price = np.zeros(days)\n",
    "    price[0] = start_price\n",
    "    # Schok and Drift\n",
    "    shock = np.zeros(days)\n",
    "    drift = np.zeros(days)\n",
    "    \n",
    "    # Run price array for number of days\n",
    "    for x in xrange(1,days):\n",
    "        \n",
    "        # Calculate Schock\n",
    "        shock[x] = np.random.normal(loc=mu * dt, scale=sigma * np.sqrt(dt))\n",
    "        # Calculate Drift\n",
    "        drift[x] = mu * dt\n",
    "        # Calculate Price\n",
    "        price[x] = price[x-1] + (price[x-1] * (drift[x] + shock[x]))\n",
    "        \n",
    "    return price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grate now let's put our function to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get start price from GOOG.head()\n",
    "start_price = 569.85\n",
    "\n",
    "for run in xrange(100):\n",
    "    plt.plot(stock_monte_carlo(start_price,days,mu,sigma))\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Price\")  \n",
    "plt.title('Monte Carlo Analysis for Google')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and get a histogram of the end results for a much larger run. (note: This could take a little while to run , depending on the number of runs chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a large numebr of runs\n",
    "runs = 10000\n",
    "\n",
    "# Create an empty matrix to hold the end price data\n",
    "simulations = np.zeros(runs)\n",
    "\n",
    "# Set the print options of numpy to only display 0-5 points from an array to suppress output\n",
    "np.set_printoptions(threshold=5)\n",
    "\n",
    "for run in xrange(runs):    \n",
    "    # Set the simulation data point as the last stock price for that run\n",
    "    simulations[run] = stock_monte_carlo(start_price,days,mu,sigma)[days-1];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our array of simulations, we can go ahead and plot a histogram ,as well as use qunatile to define our risk for this stock.\n",
    "\n",
    "For more info on quantiles, check out this link:\n",
    "http://en.wikipedia.org/wiki/Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'lll define q as the 1% empirical qunatile, this basically means that 99% of the values should fall between here\n",
    "q = np.percentile(simulations, 1)\n",
    "    \n",
    "# Now let's plot the distribution of the end prices\n",
    "plt.hist(simulations,bins=200)\n",
    "\n",
    "# Using plt.figtext to fill in some additional information onto the plot\n",
    "\n",
    "# Starting Price\n",
    "plt.figtext(0.6, 0.8, s=\"Start price: $%.2f\" %start_price)\n",
    "# Mean ending price\n",
    "plt.figtext(0.6, 0.7, \"Mean final price: $%.2f\" % simulations.mean())\n",
    "\n",
    "# Variance of the price (within 99% confidence interval)\n",
    "plt.figtext(0.6, 0.6, \"VaR(0.99): $%.2f\" % (start_price - q,))\n",
    "\n",
    "# Display 1% quantile\n",
    "plt.figtext(0.15, 0.6, \"q(0.99): $%.2f\" % q)\n",
    "\n",
    "# Plot a line at the 1% quantile result\n",
    "plt.axvline(x=q, linewidth=4, color='r')\n",
    "\n",
    "# Title\n",
    "plt.title(u\"Final price distribution for Google Stock after %s days\" % days, weight='bold');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now we have looked at the 1% empirical quantile of the final price distribution to estimate the Value at Risk for the Google stock, which looks to be $18.38 for every investment of 569.85 (the price of one inital google stock).\n",
    "\n",
    "This basically menas for every initial stock you purchase your putting about $18.38 at risk 99% of the time from our Monte Carlo Simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats on finishing the Stock Market Data Analysis project! Here are some additional quesitons and excercises for you to do:\n",
    "\n",
    "1.) Estimate the values at risk using both methods we learned in this project for a stock not related to technology.\n",
    "\n",
    "2.) Build a practice portfolio and see how well you can predict you risk values with real stock information!\n",
    "\n",
    "3.) Look further into correlatino of two stocks and see if that gives you any insight into future possible stock prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
